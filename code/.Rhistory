x <- do.call(paste0, list(paste0(df$chr, ':'),
paste0(df$start, '-'),
df$end))
subMat <- state[x,]
v <- colSums(subMat)
cellType = colnames(state)
data.frame(cellType = colnames(state), colSum = as.numeric(v))})
clust <- dcast(clust, clustNum ~ cellType)
clust <- as.matrix(clust[,2:length(clust)])
head(clust)
clust <- t(apply(clust, 1, function(x) x/sum(x)))
head(clust)
heatmap.2(clust, trace = 'none')
clust <- ddply(loci, "clustNum", function(df) {
x <- do.call(paste0, list(paste0(df$chr, ':'),
paste0(df$start, '-'),
df$end))
subMat <- state[x,]
v <- colSums(subMat)
cellType = colnames(state)
data.frame(cellType = colnames(state), colMean = as.numeric(v))})
clust <- dcast(clust, clustNum ~ cellType)
clust <- as.matrix(clust[,2:length(clust)])
clust <- t(apply(clust, 1, function(x) x/sum(x)))
clust <- ddply(loci, "clustNum", function(df) {
x <- do.call(paste0, list(paste0(df$chr, ':'),
paste0(df$start, '-'),
df$end))
subMat <- state[x,]
v <- colMeans(subMat)
cellType = colnames(state)
data.frame(cellType = colnames(state), colMean = as.numeric(v))})
clust <- dcast(clust, clustNum ~ cellType)
clust <- as.matrix(clust[,2:length(clust)])
clust <- t(apply(clust, 1, function(x) x/sum(x)))
heatmap.2(clust, trace = 'none')
clust <- ddply(loci, "clustNum", function(df) {
x <- do.call(paste0, list(paste0(df$chr, ':'),
paste0(df$start, '-'),
df$end))
subMat <- state[x,]
v <- colMeans(subMat)
cellType = colnames(state)
data.frame(cellType = colnames(state), colMean = as.numeric(v))})
clust <- dcast(clust, clustNum ~ cellType)
clust <- as.matrix(clust[,2:length(clust)])
clust <- t(apply(clust, 1, function(x) {j <- x/sum(x); log(j)}))
heatmap.2(clust, trace = 'none')
source('~/research/epigenome/rnaseq/code/explore.R')
heatmap.2(clust, trace = 'none')
heatmap.2(clust, trace = 'none', ColV = NA)
heatmap.2(clust, trace = 'none', Colv = NA)
update.packages(checkBuilt=TRUE, ask=FALSE)
update.packages()
getwd()
log(exp(1))
log(1)
log(0.99)
log(0.)
log(0.2)
log(-0.2)
version()
install.packages(
lib  = lib <- .libPaths()[1],
pkgs = as.data.frame(installed.packages(lib), stringsAsFactors=FALSE)$Package,
type = 'source'
)
install.packages(
lib  = .libPaths()[1],
pkgs = as.data.frame(installed.packages(lib), stringsAsFactors=FALSE)$Package,
type = 'source'
)
lib <- .libPaths()[1]
)install.packages(
lib  = lib,
pkgs = as.data.frame(installed.packages(lib), stringsAsFactors=FALSE)$Package,
type = 'source'
)
install.packages(
lib  = lib,
pkgs = as.data.frame(installed.packages(lib), stringsAsFactors=FALSE)$Package,
type = 'source'
)
105.81 + 666.07 + 158.17
q()
# Make plots related to specificity change diffusion and
# specifciity change for Aim 1 in NIH grant proposal
rm(list = ls())
#source('~/research/rmodules/plottingFuncs.R')
source('logisticReg2_helpers.R')
####################################################
# GLOBAL PARAMETERS
####################################################
TRAIN <- 'noyes2015_alpha0.30_BL-hughes' #'hughes2015'#
TEST <- 'hughes2015_alpha0.30'
TRAIN_LAB2 <- 'sF2F3low_d_logRegr' # For finding prediction tables
TEST_LAB2 <- 'hughes'             # For finding prediction tables
ALPHA_TRAIN <- rep('0.30', 3)
OTHER_METHODS <- c('olsf2f3Pred', 'antonSVM_l7') #'hughesPred', 'olsf2f3Pred','nnf2f3Pred')
OTHER_METHODS_LAB <- c('sF2F3low_d_olsRegr', 'svm_l7')#c('RFNH', paste0('f2f3alpha',ALPHA_TRAIN[2],'-OLS'),
#   'NN-f2f3low')
PRECOMP_FLAGS <- c(FALSE,TRUE) #c(TRUE,FALSE,TRUE)
COLS_FORMS <- c('black')#c('black', 'red', 'blue')
COLS_OTHER <- c('purple', 'green')#c('green', 'purple', 'orange')
BLACKLIST_TRAIN_SET <- FALSE      # To remove training cores from test cores
# If TRAIN ends in _BL-xxx, this is unneccesary
print(paste0("Train: ", TRAIN))
print(paste0("Test: ", TEST))
print(paste0("OtherMeths: ", OTHER_METHODS_LAB))
K <- 10                    # Number of folds for CV
MIN_POS <- 0.75            # PCC cutoff for +'s
MAX_NEG <- 0.0             # PCC cutoff for -'s
MIN_OBS_PER_FEATURE <- 10  # Min # obs. to include feature in model
if (length(OTHER_METHODS) > 0) {
PLOT_DIR <- paste0('../plots/nihGrantFigs/',TRAIN,'/','otherMethods/')
} else {
PLOT_DIR <- paste0('../plots/nihGrantFigs/',TRAIN,'/')
}
SUB_DIRS <- c(paste0(PLOT_DIR, 'bySubPos.CV/'),
paste0(PLOT_DIR, TEST, '/bySubPos/vanilla/'),
paste0(PLOT_DIR, TEST, '/bySubPos/ridge_lambda1se/'),
paste0(PLOT_DIR, TEST, '/rankPlots/'))
DO_CV <- FALSE#
DO_RIDGE <- FALSE
STANDARD_X <- TRUE     # Use the glmnet internal standardization of features
INTERCEPT <- FALSE     # Compute an intercept term
for (s in SUB_DIRS){
if (!dir.exists(s)) dir.create(s, recursive = T, showWarnings = F)
}
set.seed(87235)
# Import the data and set up the model formulas, etc...
data <- getPairDataSet(TRAIN)
TRAIN_LAB <- names(data)[1]
data <- data[[names(data)[1]]]
test.data <- getPairDataSet(TEST)
TEST_LAB <- names(test.data)[1]
test.data <- test.data[[names(test.data)[1]]]
if (BLACKLIST_TRAIN_SET) test.data <- removeTrainSet(test.data, data)
if (INTERCEPT) {
forms <- list(paste0('~',paste0(names(data)[1:4],collapse = '+')))
} else {
forms <- list(paste0('~',paste0(c(names(data)[1:4],0),collapse = '+')))
}
forms <- lapply(forms, formula)
names(forms) <- TRAIN_LAB2
if (length(OTHER_METHODS) != 0) {
PLOT_COLS <- as.list(c(COLS_FORMS, COLS_OTHER))
names(PLOT_COLS) <- c(names(forms), OTHER_METHODS_LAB)
} else {
PLOT_COLS <- as.list(COLS_FORMS)
names(PLOT_COLS) <- names(forms)
rm(list = ls())
source('logisticReg2_helpers.R')
TRAIN <- 'noyes2015_alpha0.30_BL-hughes' #'hughes2015'#
TEST <- 'hughes2015_alpha0.30'
TRAIN_LAB2 <- 'sF2F3low_d_logRegr' # For finding prediction tables
TEST_LAB2 <- 'hughes'             # For finding prediction tables
ALPHA_TRAIN <- rep('0.30', 3)
OTHER_METHODS <- c('olsf2f3Pred', 'antonSVM_l7') #'hughesPred', 'olsf2f3Pred','nnf2f3Pred')
OTHER_METHODS_LAB <- c('sF2F3low_d_olsRegr', 'svm_l7')#c('RFNH', paste0('f2f3alpha',ALPHA_TRAIN[2],'-OLS'),
PRECOMP_FLAGS <- c(FALSE,TRUE) #c(TRUE,FALSE,TRUE)
COLS_FORMS <- c('black')#c('black', 'red', 'blue')
COLS_OTHER <- c('purple', 'green')#c('green', 'purple', 'orange')
BLACKLIST_TRAIN_SET <- FALSE      # To remove training cores from test cores
print(paste0("Train: ", TRAIN))
print(paste0("Test: ", TEST))
print(paste0("OtherMeths: ", OTHER_METHODS_LAB))
rm(list = ls())
q()
packs = as.data.frame(installed.packages(.libPaths()[1]), stringsAsFactors = F)
install.packages(packs$Package)
if (!requireNamespace("BiocManager"))
install.packages("BiocManager")
BiocManager::install()
if (!requireNamespace("BiocManager"))
install.packages("BiocManager")
BiocManager::install()
.libPaths()
ip <- as.data.frame(installed.packages()[,c(1,3:4)])
rownames(ip) <- NULL
ip <- ip[is.na(ip$Priority),1:2,drop=FALSE]
print(ip, row.names=FALSE)
ip
write.table(ip, file = '~/Desktop/ip.txt', row.names = FALSE, sep = '\t',quote = F)
update.packages(ask = FALSE, checkBuilt = TRUE)
update.packages(ask = FALSE, checkBuilt = TRUE)
BiocManager::install(ask=FALSE, checkBuilt = TRUE)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.11")
install.packages("BiocManager")
install.packages("BiocManager")
BiocManager::install(ask=FALSE, checkBuilt = TRUE)
BiocManager::install(version = "3.11", ask=FALSE, checkBuilt = TRUE)
BiocManager::install(‘BSgenome.Hsapiens.UCSC.hg19’, checkBuilt = TRUE)
BiocManager::install(‘BSgenome.Hsapiens.UCSC.hg19’)
BiocManager::install("BSgenome.Hsapiens.UCSC.hg19")
BiocManager::install(version = "3.11", ask=FALSE, checkBuilt = TRUE)
BiocManager::install(version = "3.11", ask=FALSE, checkBuilt = TRUE)
?install.packages
?update.packages
.libPaths()
getOption("repos")
update.packages(ask = FALSE, checkBuilt = TRUE)
update.packages(ask = FALSE, checkBuilt = TRUE)
?
?gsePathway
?gseNCG
?gseNCG
library(data.table)
library(heatmap3)
library(RColorBrewer)
library(dynamicTreeCut)
library(ggplot2)
library(ReactomePA)
library(clusterProfiler)
library(ggrepel)
library(moduleColor)
library(EnsDb.Hsapiens.v86)
library(igraph)
suppressMessages(library(DOSE, quietly = TRUE))
suppressMessages(library(org.Hs.eg.db, quietly = TRUE))
suppressMessages(library(enrichplot, quietly = TRUE))
suppressMessages(library(ggnewscale, quietly = TRUE))
?gseNCG
?gseGO
?gseDO
update.packages(checkBuilt = TRUE)
update.packages(checkBuilt = TRUE)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
pkgs <- rownames(installed.packages())
BiocManager::install(pkgs, type = "source", checkBuilt = TRUE)
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
setwd('~/research/jointInterfaceLearning/rCLAMPS/')
setwd('~/research/jointInterfaceLearning/rCLAMPS/code/')
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
setwd('~/research/mutZF/data/pwms/singleFing/hughes2015/stepwiseReg/')
library(plyr)
rm(list = ls())
inputFile <- 'B1H.motifs.csv'
library(plyr)
rm(list = ls())
inputFile <- 'B1H.motifs.csv'
makeLongFrame <- function(df) {
# Reformats the dataframe from Hughes 2015 Nat Biotech (B1H.motifs.csv)
# so that the -1 to 6 positions of the core helix sequence is extracted from the protein sequence
# and each row is a single column of a pwm.
# Finds the core seq based on regex.
pat <- '["A-Z"]{7}H["A-Z"]{3,7}["HC"]$'
noMatch <- 0
OLS.ID <- c()
seq <- c()
coreSeq <- c()
bpos <- c()
A <- c()
C <- c()
G <- c()
T <- c()
# Protein
for (i in 1:nrow(df)) {
ols.id <- df$OLS.ID[i]
prot <- df$ZF.protein.sequence[i]
start <- regexpr(pat, prot)
if (start == -1) {
noMatch <- noMatch + 1
next
}
helix <- substr(prot, start, start+6)
core <- paste0(substr(helix,1,1), substr(helix,3,3),
substr(helix,4,4), substr(helix,7,7))
# Base position
for (j in 1:4) {
OLS.ID <- c(OLS.ID, ols.id)
seq <- c(seq, helix)
coreSeq <- c(coreSeq, core)
bpos <- c(bpos, j)
start <- 5 + (j-1)*4
logOdds <- as.numeric(df[i,start:(start+3)])
A <- c(A, logOdds[1])
C <- c(C, logOdds[2])
G <- c(G, logOdds[3])
T <- c(T, logOdds[4])
}
}
print(paste("No match to regex for", noMatch, "examples."))
df <- data.frame(OLS.ID = OLS.ID, bpos = bpos, coreSeq = coreSeq,
A = A, C = C, G = G, T = T)
df <- df[order(df$coreSeq),]
}
energiesToProbs <- function(data, id.cols) {
# Coverts a long data frame of per-base-position log-odds
# scores to long data frame as a PFM, where log odds
# are converting by exponentiating (base e) and then
# renormalizing to a distribution.
x <- ddply(data, id.cols, function(df) {
vals <- as.numeric(subset(df, select = c('A', 'C', 'G', 'T')))
vals <- exp(vals)
vals <- vals/sum(vals)
data.frame(coreSeq = df$coreSeq,
A = vals[1], C = vals[2], G = vals[3], T = vals[4])
})
x
}
scaleLogOdds <- function(data, id.cols) {
# Return a new data frame where energies have been rescaled
# by a constant factor.  To compute this factor, for each
# PWM an energy normalzation constant is chosen such that
# a 50-fold preference is observed between the most and least
# preferred base in the most selective base position for each PWM.
c <- log(50)
#print(head(data))
x <- ddply(data, id.cols, function(df) {
vals <- as.matrix(subset(df, select = c('A', 'C', 'G', 'T')))
probs <- exp(vals)
probs <- probs/rowSums(probs)
#print(vals)
#print(probs)
maxDiffRow <- which.max(apply(probs, 1, function(x) (max(x) - min(x))))
w_i <- vals[maxDiffRow,][which.min(probs[maxDiffRow,])]
w_j <- vals[maxDiffRow,][which.max(probs[maxDiffRow,])]
#print(maxDiffRow)
B <- c/(w_j - w_i)
#print(paste(w_j, w_i, B))
data.frame(coreSeq = df$coreSeq[1], B = B, numRows = nrow(df))
})
#print(head(x))
scaleFact <- c()
data <- data[order(data[[id.cols]]),]
for (id in x[[id.cols]])
scaleFact <- c(scaleFact, rep(x$B[x[[id.cols]] == id],
x$numRows[x[[id.cols]] == id]))
for (nuc in c('A', 'C', 'G', 'T')) data[[nuc]] <- scaleFact*data[[nuc]]
data <- data[order(data$coreSeq),]
data
}
avgOverRepCores <- function(data) {
# Takes a set of experimental PWMs as inputs and averages
# returns a new set with no redundant core sequences by
# averaging across all pwms for an identical core seq.
ddply(data, c("coreSeq", "bpos"), function(df) {
data.frame(A = mean(df$A), C = mean(df$C),
G = mean(df$G), T = mean(df$T))})
}
# Read in the Hughes data file
data.raw <- read.csv(inputFile, header = T)
data.raw
# Convert to a long data frame, saving only the
# necessary information.
print("Converting to long format table.")
data.long <- makeLongFrame(data.raw)
write.table(data.long, 'B1H.motifs.long.txt', row.names=F,quote=F)
# Convert each row from log-odds to frequencies by simply
# exponentiating (base e) and renormalizing.
print("Conveting raw energies to frequencies (B = 1).")
data.long.pfm <- energiesToProbs(data.long, c('OLS.ID', 'bpos'))
data.long.pfm <- data.long.pfm[order(data.long.pfm$coreSeq),]
data.long.pfm
write.table(data.long.pfm, 'B1H.motifs.long.pfm.txt', row.names=F,quote=F)
# Re-scale the log-odds PWMs by a constant
print("Rescaling energies to fix IC.")
data.long.scaled <- scaleLogOdds(data.long, 'OLS.ID')
data.long.pfm.scaled <- energiesToProbs(data.long.scaled,
c('OLS.ID', 'bpos'))
data.long.pfm.scaled <-
data.long.pfm.scaled[order(data.long.pfm.scaled$coreSeq),]
write.table(data.long.pfm.scaled, 'B1H.motifs.long.pfm.scaled.txt',
row.names=F,quote=F)
data.long.pfm.scaled
# Take average across different Hughes PWMs with same core seq
print("Averaging across identical core sequences.")
data.long.pfm.noReps <- avgOverRepCores(data.long.pfm)
data.long.pfm.scaled.noReps <- avgOverRepCores(data.long.pfm.scaled)
write.table(data.long.pfm.noReps,
'B1H.motifs.long.pfm.noReps.txt',
row.names = FALSE, quote = FALSE)
write.table(data.long.pfm.scaled.noReps,
'B1H.motifs.long.pfm.scaled.noReps.txt',
row.names = FALSE, quote = FALSE)
data.long.pfm.scaled.noReps
length(unique(data.long.pfm.scaled.noReps$coreSeq))
10396/4
41269.62/60/60
setwd('~/research/jointInterfaceLearning/rCLAMPS/code/')
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fracPCCge.tab[pcc == 0.5]
fracPCCge.tab
fitInfo
fitInfo <- fitInfo[ic.exp >= 0.5]
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
exclude <- which(fitInfo$ic.exp < 0.25 & fitInfo$ic.pred < 0.25)
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fitInfo
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fitInfo
1744/2296
# Trim the PWMs
pwmTrim <- data.table(prot = unique(fitInfo$prot))
pwmTrim
# Trim the PWMs
icThresh <- 0.3
pwmTrim$start <- sapply(pwmTrim$prot, function(x) {min(which(fitInfo[prot == x]$ic.exp >= icThresh))})
pwmTrim$end <- sapply(pwmTrim$prot, function(x) {max(which(fitInfo[prot == x]$ic.exp >= icThresh))})
pwmTrim
fitInfo <- merge(fitInfo, pwmTrim, by = 'prot')
fitInfo
# Reproduction of Figures in the zf-C2H2 figures for article
# Plot the model performance in hold-one-out cross validation when
# when assuming the alignment based on gibbs sampling from all proteins
library(plyr)
library(data.table)
library(ggplot2)
library(RColorBrewer)
library(broom)
library(lvplot)
###########################
# Figure 2
###########################
# Uses output from 'holdoutRetrainGLM.py', where the GLM was retrained with
# each distinct set of binding amino acid residue combinations' protiens held out separately,
# to understand the expected de novo predictive performance of rCLAMPS in
# a strict hold-out cross-validation setup.
rm(list = ls())
MWID <- '4'
AMINO <- c('A','C','D','E','F','G','H','I','K','L',
'M','N','P','Q','R','S','T','V','W','Y')
inDir <- paste0('../my_results/zf-C2H2_100_15_seedB1H/')
#inDir <- paste0('../my_results/zf-C2H2_100_25_seedFFSall_noRescale/')
#inDir <- paste0('../my_results/zf-C2H2_100_25_seedFFSall/')
#inDir <- paste0('../my_results/zf-C2H2_ffsOnly_iter1/')
infile <- paste0(inDir,'pccTable_underS_holdOneOut.txt')
outdir <- paste0(inDir, 'plots/')
dir.create(outdir,showWarnings = FALSE,recursive = TRUE)
# Fit when using strict holdout validation setup
fitInfo <- fread(infile)
#fitInfo <- fitInfo[!(ic.exp < 0.5)]
fitInfo$domPos <- (fitInfo$pos-1)%%3
fitInfo$pos <- factor(fitInfo$pos)
fitInfo$domPos <- factor(fitInfo$domPos)
fitInfo$pccAgree <- ifelse(fitInfo$pcc >= 0.5, TRUE, FALSE)
fitInfo$testType <- 'hold-one-out'
# Trim the PWMs
icThresh <- 0.3
pwmTrim <- data.table(prot = unique(fitInfo$prot))
fitInfo[prot == x]$ic.exp >= icThresh
fitInfo[prot == 'Blimp-1']$ic.exp >= icThresh
fitInfo[prot == 'Blimp-1']$ic.exp
fitInfo
fitInfo <- fitInfo[pos >= start & pos <= end]
# Reproduction of Figures in the zf-C2H2 figures for article
# Plot the model performance in hold-one-out cross validation when
# when assuming the alignment based on gibbs sampling from all proteins
library(plyr)
library(data.table)
library(ggplot2)
library(RColorBrewer)
library(broom)
library(lvplot)
###########################
# Figure 2
###########################
# Uses output from 'holdoutRetrainGLM.py', where the GLM was retrained with
# each distinct set of binding amino acid residue combinations' protiens held out separately,
# to understand the expected de novo predictive performance of rCLAMPS in
# a strict hold-out cross-validation setup.
rm(list = ls())
MWID <- '4'
AMINO <- c('A','C','D','E','F','G','H','I','K','L',
'M','N','P','Q','R','S','T','V','W','Y')
inDir <- paste0('../my_results/zf-C2H2_100_15_seedB1H/')
#inDir <- paste0('../my_results/zf-C2H2_100_25_seedFFSall_noRescale/')
#inDir <- paste0('../my_results/zf-C2H2_100_25_seedFFSall/')
#inDir <- paste0('../my_results/zf-C2H2_ffsOnly_iter1/')
infile <- paste0(inDir,'pccTable_underS_holdOneOut.txt')
outdir <- paste0(inDir, 'plots/')
dir.create(outdir,showWarnings = FALSE,recursive = TRUE)
# Fit when using strict holdout validation setup
fitInfo <- fread(infile)
#fitInfo <- fitInfo[!(ic.exp < 0.5)]
fitInfo$domPos <- (fitInfo$pos-1)%%3
fitInfo$domPos <- factor(fitInfo$domPos)
fitInfo$pccAgree <- ifelse(fitInfo$pcc >= 0.5, TRUE, FALSE)
fitInfo$testType <- 'hold-one-out'
# Trim the PWMs
icThresh <- 0.3
pwmTrim <- data.table(prot = unique(fitInfo$prot))
pwmTrim$start <- sapply(pwmTrim$prot, function(x) {min(which(fitInfo[prot == x]$ic.exp >= icThresh))})
pwmTrim$end <- sapply(pwmTrim$prot, function(x) {max(which(fitInfo[prot == x]$ic.exp >= icThresh))})
fitInfo <- merge(fitInfo, pwmTrim, by = 'prot')
fitInfo <- fitInfo[pos >= start & pos <= end]
fitInfo
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fracPCCge.tab[pcc == 0.5]
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fracPCCge.tab[pcc == 0.5]
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fracPCCge.tab[pcc == 0.5]
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fracPCCge.tab[pcc == 0.5]
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
source("~/research/jointInterfaceLearning/rCLAMPS/code/analysis_manuscript_zf-C2H2.R")
fracPCCge.tab[pcc == 0.5]
